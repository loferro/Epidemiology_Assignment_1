---
title: "Assignment 1"
author: "Ferrara Lorenzo, Lucchini Marco"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r include=FALSE}
knitr::opts_chunk$set( echo=F )
```

## Description
### The data were collected during a study of the settlement pattern of common terns on a small islet in the Delta d’Ebre (Hernandez and Ruiz, range3), particularly in the mouths of the Ebre river. The islet was inspected at two-day intervals throughout the range0 breeding season. The data include the location of each nest, its elevation above sea level, and elevations at a number of additional points (points without nest) on the islet. In the file called elevationsIslet.txt, contains the information of the coordinates and elevation above sea, and in file, called poly84.txt contains the coordinates of the borders of the islet. The aim is to predict the elevation above sea level along the small islet using a kriging interpolation. 

```{r eval=FALSE, include=FALSE}
# load("Data.RData")
```

```{r cache=F}
poly84 <- read.delim("poly84.txt")
names(poly84)= c("x", "y", "data")
head(poly84)
elevationsIslet <- read.delim("elevationsIslet.txt")
head(elevationsIslet)
```

### 1) Explore the requirement of stationary mean of the process. In case this requirement is not met, detrend the data to ensure that the process is stationary in mean. Discuss the results and show the plot of the results

Firstly, we plot the locations to see the spatial distribution of the data

```{r include=FALSE}
library(geoR)
library(gstat)
# library(lattice)
library(sp)
```

```{r cache=F}
dataset = elevationsIslet
data_for_bubble = dataset
coordinates(data_for_bubble) <- c('x','y')
bubble(data_for_bubble,'data',do.log=TRUE,key.space='bottom')
rm(data_for_bubble)
```

METTERLO IN SCALA D COLORI


We also look at the distribution in relation to the x-coordinates (E-W) and y-coordinates(N-S).

```{r cache=F}
geodataset <- as.geodata(dataset)
plot(geodataset, borders = poly84[,1:2])[1]
```


```{r}
par(mfrow=c(1,2))
with(geodataset , plot(coords[, 1], data, xlab = "x",ylab = "data", pch = 20, cex = 0.7))
#add lowess smoother
lines(lowess(geodataset$data ~ geodataset$coords[, 1]))

with(geodataset , plot(coords[, 2], data, xlab = "y",ylab = "data", pch = 20, cex = 0.7))
#add lowess smoother
lines(lowess(geodataset$data ~ geodataset$coords[, 2]))
```

The plots show a concentration of high values in the east (data are centered in x=50) and in the north (data are very dense from y=0 to y=50) 

The process doesn't seem stationary, indeed there is a clear quadratic trend along the x direction. In addition we try using the y direction as regressor, to find a possible linear or quadratic trend.

```{r cache=F}
lm <- lm(data ~ x + y + I(x^2) + I(y^2), data = dataset)
summary(lm)
```

The linear term in y doesn't seem significant, so we remove it.

```{r cache=F}
lm <- lm(data ~ x + I(x^2) + I(y^2), data = dataset)
summary(lm)
```

Now we have obtained a model in which all regressor seem to be significant => So we save the residuals of our linear model and look at the de-trended data:

```{r cache=F}
residuals <- round(residuals(lm), digits = 3)
dataset.new <- cbind(dataset, residuals)
head(dataset.new)


geodataset.residuals <- as.geodata(dataset.new, data.col = 4)
plot(geodataset.residuals)
```

```{r}
par(mfrow=c(1,2))
with(geodataset.residuals , plot(coords[, 1], data, xlab = "x",ylab = "data", pch = 20, cex = 0.7))
#add lowess smoother
lines(lowess(geodataset.residuals$data ~ geodataset.residuals$coords[, 1]))

with(geodataset.residuals , plot(coords[, 2], data, xlab = "y",ylab = "data", pch = 20, cex = 0.7))
#add lowess smoother
lines(lowess(geodataset.residuals$data ~ geodataset.residuals$coords[, 2]))
```

We don't notice any particular trend so this new dataset seems stationary! And now the data seems distributed around 0.

<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### 2) Explore the spatial dependence of the elevation variable using the variogram cloud and bins and the empirical variogram. Discuss the results and plot them

### Variogram Could
```{r cache=F}
vario.cloud.classical <- variog(geodata = geodataset.residuals, option = "cloud", estimator.type = "classical")
plot(vario.cloud.classical, main = "CLOUD", cex.main = 1, cex.lab = 1)
```

The variability at small distances appears a bit greater than that for larger distances. 
=> We reduce the density of the plot by reducing the maximum distance over which the variance are calculate. 

```{r cache=F}
dist.max.data  <- 120
#i chose 120 since it's when the variance becomes much smaller


vario.cloud.classical <- variog(geodata = geodataset.residuals,option = "cloud", estimator.type = "classical", max.dist = dist.max.data)

plot(vario.cloud.classical, main = "CLOUD", cex.main = 1, cex.lab = 1)
```

```{r cache=F}

vario.bc.classical <- variog(geodata = geodataset.residuals, option = "bin",bin.cloud = TRUE, pairs.min = 30, max.dist = dist.max.data,estimator.type = "classical")

plot(vario.bc.classical, bin.cloud = TRUE, cex.lab = 1, main = "\nBINNED BOXPLOTS",cex.main = 1)
```

```{r cache=F}
# round(vario.bc.classical$bins.lim, 2)
```

```{r cache=F}
vario.bc.classical$ind.bin
```

=> All the bins have at least pairs.min=30 observations each, indeed they have:

```{r cache=F}
vario.bc.classical$n
```

Empirical Variogram
```{r cache=F}
vario.b.classical <- variog(geodata = geodataset.residuals, option = "bin",pairs.min = 30, max.dist = dist.max.data, estimator.type = "classical",uvec = seq(1, dist.max.data, l = 13))

plot(vario.b.classical, main = "EMPIRICAL VARIOGRAM (Classical)\nBINNED",cex.main = 1, cex.lab = 1, cex = 1, pch = 16)
```

```{r cache=F}
vario.b.robust <- variog(geodata = geodataset.residuals, option = "bin",pairs.min = 30, max.dist = dist.max.data, estimator.type = "modulus",uvec = seq(1, dist.max.data, l = 13))

plot(vario.b.robust, main = "EMPIRICAL VARIOGRAM (Robust)\nBINNED",cex.main = 1, cex.lab = 1, cex = 1, pch = 16)
```

In the variogram of the residuals the values increases until certain distance, and then they keep constant.

### 3) Check the hypothesis of the spatial independence

To check the hypothesis of the spatial independence we use a Monte Carlo approach 

```{r cache=F}
set.seed(1) #fix the seed
indep.env <- variog.mc.env(geodataset.residuals, obj.variog = vario.b.robust,nsim = 1000)
plot(vario.b.robust, envelope = indep.env, main = "CONFIDENCE BANDS FOR INDEPENDENT MODEL",lwd = 2, pch = 16)
```

All the values of the empirical variogram are inside the envelope, therefore the process has no spatial dependence.

### 4) Check the isotropy property of the process. Comment the results, it’s not necessary to overcome the anisotropy.

To check the anisotropy we need to compute the directional variogram in the 4 main directions: 0º, 45º,90º and 135º. 

<!-- classical -->

```{r cache=F}
variod <- variog4(geodata = geodataset.residuals, option = "bin",pairs.min = 30, max.dist = dist.max.data, estimator.type = "classical",uvec = seq(1, dist.max.data, l = 13))

plot(variod, lyt = 2, legend = FALSE)
#plot the directional variogram
legend(x = "bottomright", inset = 0.01, lty = c(1, 2, 3, 4),col = c("black", "red", "green", "blue"), legend = c("0º","45º", "90º", "135º"), cex = 0.5)
```

<!-- oppure modulus? -->

```{r cache=F}
variod <- variog4(geodata = geodataset.residuals, option = "bin",pairs.min = 30, max.dist = dist.max.data, estimator.type = "modulus",uvec = seq(1, dist.max.data, l = 13))

plot(variod, lyt = 2, legend = FALSE)
#plot the directional variogram
legend(x = "bottomright", inset = 0.01, lty = c(1, 2, 3, 4),col = c("black", "red", "green", "blue"), legend = c("0º","45º", "90º", "135º"), cex = 0.5)
```

The directional variograms don't seem to be perfectly overlapping: they might have the a different sill, in particular the variogram seems to have a higher value along the 90° direction => Geometrical anistropy

Let's also analyse the range observing the Rose Diagram:

```{r cache=F}
source("RoseDiagram.R")

NumCases = length(variod$`0`)

# crit.val~sill
# max.dist = massimo valore di dstanza
rose.diagram(data.var = geodataset.residuals$data, data.cds = geodataset.residuals$coord,
max.dist = 90, numcases = NumCases, numdirec = 4, poly.tnd = "cte",
crit.val = 120)

```


We can observe that the Rose diagram is more or less a circle. At different directions, the variance is reached
more or less at the same range. Then, this process is isotropic.

OPPURE

We notice that the Rose diagram is not perfectly circular: it is slightly elliptical, with major range in the 90 direction => Zonal anistropy.

=> In conclusion we have a combined anisotropy, so we can't make the assumption of isotropic process, which are necessary for the correct use of the kriging techniques, since the theoretical variograms used for krigring are based on isotropic models.


MAGARI è IL CASO DI FARE IL CLOUD CON LA ROBUST WAY?

### 5) Propose four theoretical variograms and estimate the parameters via restricted maximum likelihood or weighed least square. Select the two variograms which best fit the data. Explain the parameters of the chosen variogram (sill, nugget, range and kappa).

<!-- The κ parameter controls the smoothness of the process. -->
<!-- The higher is κ, the smoother the spatial process. -->
<!-- Special cases κ = 1/2 exponential model and κ → ∞ Gaussian mode -->


```{r cache=F}

variogramma <- variog(geodata = geodataset.residuals, max.dist = 120)
par(mfrow=c(1,2))
plot(variogramma)
plot(vario.b.robust)

# BHO USERò IL VARIO.B.ROBUST
variogramma = vario.b.robust

# windows(); eyefit(variogramma, silent = FALSE)

```

<!-- tau_sq = nugget -->
<!-- sigma_sq = sill -->

```{r cache=F, include=FALSE}
 
wls.exponential <- variofit(variogramma, cov.model = "exponential", ini = c(91, 25), fix.nugget = F, weights = "cressie")

wls.gaussian <- variofit(variogramma, cov.model = "gaussian", ini = c(86, 8), fix.nugget = F, weights = "cressie")

wls.spherical <- variofit(variogramma, cov.model = "spherical", ini = c(84, 32), fix.nugget = F, weights = "cressie")

wls.matern <- variofit(variogramma, cov.model = "matern", ini = c(88, 19), fix.nugget = F, fix.kappa = T, kappa = 10.27, weights = "cressie")
wls.matern


wls.matern <- variofit(variogramma, cov.model = "matern", ini = c(88, 19), fix.nugget = F, fix.kappa = T, kappa = 0.27, weights = "cressie")
wls.matern


wls.matern <- variofit(variogramma, cov.model = "matern", ini = c(88, 19), fix.nugget = F, fix.kappa = F, kappa = 0.27, weights = "cressie")
wls.matern


wls.matern <- variofit(variogramma, cov.model = "matern", ini = c(88, 19), fix.nugget = F, weights = "cressie")
wls.matern
```

```{r}
temp=c()
for(i in seq(1e-5,10,10/100)){
  wls.matern <- variofit(variogramma, cov.model = "matern", ini = c(88, 19), fix.nugget = F, fix.kappa = T, kappa = i, weights = "cressie")
  temp = c(temp, wls.matern$value)
}
plot(seq(1e-5,10,10/100), temp, type="l")
```

perchè se gli impongo un valore viene un weighted sum minore che nel normale fitting?

#### Exponential

```{r cache=F}
wls.exponential
```

#### Gaussian
```{r cache=F}
wls.gaussian
```

#### Spherical
```{r cache=F}
wls.spherical
```

#### Matern
```{r cache=F}
wls.matern
```

$k=1$ so the Matern model redces to a 


```{r cache=F, include=F}
plot(variogramma, main = "PARAMETRIC VARIOGRAMS", cex.main = 1, pch = 16) #empirical variogram
lines(wls.exponential, lwd = 2, col = "red", max.dist = dist.max.data) # add exponential
lines(wls.gaussian, lwd = 2, col = "blue", max.dist = dist.max.data) # add guassian
lines(wls.spherical, lwd = 2, col = "green3", max.dist = dist.max.data) # add spherical
lines(wls.matern, lwd = 2, col = "yellow", max.dist = dist.max.data) # add matern
legend(x = "bottomright", inset = 0.01, lty = c(1, 1), col = c("red", "blue", "green3", "yellow"), 
       legend = c("Exponential", "Gaussian", "Spherical", "Matern"), cex = 1)

```

#### Computing envelops for empirical variograms.
```{r cache=F, include=FALSE}
set.seed(10)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = wls.exponential, nsim = 999)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = wls.gaussian, nsim = 999)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = wls.spherical, nsim = 999)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = wls.matern, nsim = 999)
```

```{R cache=F}
par(mfrow = c(1, 4))
plot(variogramma, main = "Exponential", lwd = 2, pch = 16, envelope = env)
plot(variogramma, main = "Gaussian", lwd = 2, pch = 16, envelope = env)
plot(variogramma, main = "Spherical", lwd = 2, pch = 16, envelope = env)
plot(variogramma, main = "Matern", lwd = 2, pch = 16, envelope = env)
```


#### Let's compare the different models
```{r cache=F}

temp = data.frame( model = c("exponential", 
                      "gaussian", 
                      "spherical", 
                      "matern"), 
            sum.of.squares = c(summary(wls.exponential)$sum.of.squares, 
                               summary(wls.gaussian)$sum.of.squares, 
                               summary(wls.spherical)$sum.of.squares, 
                               summary(wls.matern)$sum.of.squares)
)

temp[ order(temp$sum.of.squares),]

```



```{r cache=F, include=FALSE}
lk.exponential <- likfit(geodataset.residuals, cov.model = "exponential", ini = c(91, 25), lik.method = "REML")

lk.gaussian <- likfit(geodataset.residuals, cov.model = "gaussian", ini = c(86, 8), lik.method = "REML")

lk.spherical <- likfit(geodataset.residuals, cov.model = "spherical", ini = c(91, 22), lik.method = "REML")

lk.matern <- likfit(geodataset.residuals, cov.model = "matern", ini = c(88, 19), fix.nugget = F, fix.kappa = F, kappa = 0.27, lik.method = "REML")
lk.matern <- likfit(geodataset.residuals, cov.model = "matern", ini = c(91,22), fix.nugget = F, fix.kappa = F, kappa = 0.27, lik.method = "REML")

```

#### Exponential
```{r cache=F}
lk.exponential
```

#### Gaussian
```{r cache=F}
lk.gaussian
```

#### Spherical
```{r cache=F}
lk.spherical
```


#### Matern
```{r cache=F}
lk.matern
```

```{r cache=F}
plot(variogramma, main = "PARAMETRIC VARIOGRAMS", cex.main = 1, pch = 16) #empirical variogram
lines(lk.exponential, lwd = 2, col = "red", max.dist = dist.max.data) # add exponential
lines(lk.gaussian, lwd = 2, col = "blue", max.dist = dist.max.data) # add guassian
lines(lk.spherical, lwd = 2, col = "green3", max.dist = dist.max.data) # add spherical
lines(lk.matern, lwd = 2, col = "yellow", max.dist = dist.max.data) # add matern
legend(x = "bottomright", inset = 0.01, lty = c(1, 1), col = c("red",
"blue", "green3", "yellow"), legend = c("Exponential", "Gaussian",
"Spherical", "Matern"), cex = 1)
```

```{r cache=F, include=FALSE}
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = lk.exponential)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = lk.gaussian)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = lk.spherical)
env <- variog.model.env(geodataset.residuals, obj.variog = variogramma, model.pars = lk.matern)
```

```{R cache=F}
par(mfrow = c(1, 4))
plot(variogramma, main = "Exponential", lwd = 2, pch = 16, envelope = env)
plot(variogramma, main = "Gaussian", lwd = 2, pch = 16, envelope = env, cex.main = 1)
plot(variogramma, main = "Spherical", lwd = 2, pch = 16, envelope = env, cex.main = 1)
plot(variogramma,main = "Matern", lwd = 2, pch = 16, envelope = env, cex.main = 1)
```

All the simulated variograms contain the empirical variogram so we don't have evidence to exclude any model.
<!-- ???? -->

Let's compare the different models
```{r cache=F}

temp.lk = data.frame( model = c("exponential", 
                      "gaussian", 
                      "spherical", 
                      "matern"), 
            loglikelihood = c(lk.exponential$loglik, 
                               lk.gaussian$loglik, 
                               lk.spherical$loglik,
                               lk.matern$loglik
                               )
)

temp.lk[ order(temp$loglikelihood, decreasing = T),]
```

The two fitted models with the highest loglikelihood are the Matern model and the Gaussian model. So we'll use these two to perform the kriging prediction step.

### 6) Predict the elevations along all the area of study using the two variogram selected in point 4. Discuss the type of kriging chosen:
### a. Compare both kriging predictions using cross-validation, and propose the best model.
### b. Show the predictions and their standard errors. 

```{r cache=F}
rnx <- range(geodataset$coords[,1]) #Minimum and maximum of the latitude
rny <- range(geodataset$coords[,2]) #Minimum and maximum of the longitude
newx.grid <- seq(rnx[1],rnx[2],l=51) #Create a sequence from minimum to
#maximum of the latitude of 51 points
newy.grid <- seq(rny[1],rny[2],l=51) #Create a sequence from minimum to
#maximum of the longitude of 51 points
dsgr.grid <- expand.grid(newx=newx.grid, newy=newy.grid) #expand, to create a grid

points(geodataset, ylim=range(poly84$y))
lines(poly84[,1:2], type="l")
points(dsgr.grid, pch = 19, col = 4, cex = 0.25)
```

#### Gaussian

```{r cache=F}
kc.gaussian<-krige.conv(geodataset,locations= dsgr.grid,
krige =krige.control(type.krige="OK",obj.m = lk.gaussian,
trend.l="1st" ,trend.d= "1st"))
image(kc.gaussian,xlim=range(dataset$x),ylim=range(dataset$y), borders = poly84)
```

```{r cache=F}
contour(kc.gaussian,filled= TRUE,
coords.data=geodataset$coords,col=terrain.colors(31),xlim=range(dataset$x),ylim=range(dataset$y),borders = poly84)
```

```{r cache=F}
contour(kc.gaussian,filled= TRUE,val=sqrt(kc.gaussian$krige.var),
coords.data=geodataset$coords,xlim=range(dataset$x),ylim=range(dataset$y),
col = gray(seq(1, 0.1, l = 30)), main="Plot of Standard Deviation",borders = poly84)
```
 
```{r cache=F}
xv.gaussian <- xvalid(geodataset, model =lk.gaussian, reestimate = F)

names(xv.gaussian)
```

```{r cache=F}
VC1.gaussian <- abs(mean(xv.gaussian$error/sqrt(xv.gaussian$krige.var)))
VC2.gaussian <- sqrt(mean((xv.gaussian$error/sqrt(xv.gaussian$krige.var))^2))
VC3.gaussian <- sqrt(mean(xv.gaussian$error^2))

data.frame( index = c("VC1", "VC2", "VC3"), value = c(VC1.gaussian, VC2.gaussian, VC3.gaussian) )

```


<!-- ############################ -->

#### Matern 
```{r cache=F}
kc.matern<-krige.conv(geodataset,locations= dsgr.grid,
krige = krige.control(type.krige="OK",obj.m = lk.matern, trend.l="1st" ,trend.d= "1st"))
image(kc.matern, xlim=range(dataset$x),ylim=range(dataset$y), borders = poly84)
```

```{r cache=F}
contour(kc.matern,filled= TRUE,
coords.data=geodataset$coords,xlim=range(dataset$x),ylim=range(dataset$y), col=terrain.colors(30), borders = poly84)
```

```{r cache=F}
contour(kc.matern,filled= TRUE,val=sqrt(kc.matern$krige.var),
coords.data=geodataset$coords,xlim=range(dataset$x),ylim=range(dataset$y), col = gray(seq(1, 0.1, l = 30)), borders = poly84[,1:3])
```

```{r cache=F}
xv.matern <- xvalid(geodataset, model =lk.matern, reestimate = F)
```

```{r cache=F}
VC1.matern <- abs(mean(xv.matern$error/sqrt(xv.matern$krige.var)))
VC2.matern <- sqrt(mean((xv.matern$error/sqrt(xv.matern$krige.var))^2))
VC3.matern <- sqrt(mean(xv.matern$error^2))

data.frame( index = c("VC1", "VC2", "VC3"), value = c(VC1.matern, VC2.matern, VC3.matern) )
```








```{r cache=F}
save.image("Data.RData")
```




